{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:25.702710Z",
     "start_time": "2020-11-06T05:41:24.831779Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:25.980505Z",
     "start_time": "2020-11-06T05:41:25.706040Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "\n",
    "train = pd.read_csv('./open/train.csv', encoding='utf-8')\n",
    "test_x = pd.read_csv('./open/test_x.csv', encoding='utf-8')\n",
    "submission = pd.read_csv('./open/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:25.986249Z",
     "start_time": "2020-11-06T05:41:25.983338Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.loc[:, 'text']\n",
    "y = train.loc[:, 'author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:26.044032Z",
     "start_time": "2020-11-06T05:41:25.987990Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터라이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:28.905817Z",
     "start_time": "2020-11-06T05:41:26.046382Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 모델들 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:29.501637Z",
     "start_time": "2020-11-06T05:41:28.907530Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(random_state=13)))\n",
    "models.append(('MultinomialNB', MultinomialNB()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state=13, n_jobs=-1)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=13)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=13)))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state=13)))\n",
    "models.append(('LGBMClassifier', LGBMClassifier(random_state=13)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)))\n",
    "models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', random_state=13)))\n",
    "models.append(('XgBoost', XGBClassifier(learning_rate=0.1, max_depth=3, random_state=13, n_jobs=-1)))\n",
    "models.append(('RidgeClassifier', RidgeClassifier(random_state=13)))\n",
    "models.append(('SGDClassifier', SGDClassifier(random_state=13, loss='modified_huber')))\n",
    "# models.append(('RidgeClassifierCV', RidgeClassifierCV(cv=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:41:29.515779Z",
     "start_time": "2020-11-06T05:41:29.505319Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=13, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False)),\n",
       " ('MultinomialNB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('RandomForestClassifier',\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=13, verbose=0,\n",
       "                         warm_start=False)),\n",
       " ('DecisionTreeClassifier',\n",
       "  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=13, splitter='best')),\n",
       " ('AdaBoostClassifier',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                     n_estimators=50, random_state=13)),\n",
       " ('GradientBoostingClassifier',\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=13, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)),\n",
       " ('LGBMClassifier',\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=13, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
       " ('KNeighborsClassifier',\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                       weights='uniform')),\n",
       " ('LinearSVC',\n",
       "  LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "            penalty='l2', random_state=13, tol=0.0001, verbose=0)),\n",
       " ('XgBoost',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.1, max_delta_step=None, max_depth=3,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                objective='binary:logistic', random_state=13, reg_alpha=None,\n",
       "                reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                tree_method=None, validate_parameters=None, verbosity=None)),\n",
       " ('RidgeClassifier',\n",
       "  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                  max_iter=None, normalize=False, random_state=13, solver='auto',\n",
       "                  tol=0.001)),\n",
       " ('SGDClassifier',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "                max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "                power_t=0.5, random_state=13, shuffle=True, tol=0.001,\n",
       "                validation_fraction=0.1, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:46:01.563495Z",
     "start_time": "2020-11-06T05:41:29.518876Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:46:01.582106Z",
     "start_time": "2020-11-06T05:46:01.565462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.991982</td>\n",
       "      <td>0.614674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.991982</td>\n",
       "      <td>0.486091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.882051</td>\n",
       "      <td>0.731718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.868281</td>\n",
       "      <td>0.730199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.867682</td>\n",
       "      <td>0.732932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.825407</td>\n",
       "      <td>0.722060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.758454</td>\n",
       "      <td>0.679422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.729975</td>\n",
       "      <td>0.649903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.580216</td>\n",
       "      <td>0.560313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.527658</td>\n",
       "      <td>0.517128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.479943</td>\n",
       "      <td>0.480260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.459925</td>\n",
       "      <td>0.271441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model name  train score  test score\n",
       "0       RandomForestClassifier     0.991982    0.614674\n",
       "1       DecisionTreeClassifier     0.991982    0.486091\n",
       "2              RidgeClassifier     0.882051    0.731718\n",
       "3                    LinearSVC     0.868281    0.730199\n",
       "4                SGDClassifier     0.867682    0.732932\n",
       "5           LogisticRegression     0.825407    0.722060\n",
       "6                MultinomialNB     0.758454    0.679422\n",
       "7               LGBMClassifier     0.729975    0.649903\n",
       "8   GradientBoostingClassifier     0.580216    0.560313\n",
       "9                      XgBoost     0.527658    0.517128\n",
       "10          AdaBoostClassifier     0.479943    0.480260\n",
       "11        KNeighborsClassifier     0.459925    0.271441"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score}) \n",
    "result.sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:46:01.589915Z",
     "start_time": "2020-11-06T05:46:01.584591Z"
    }
   },
   "outputs": [],
   "source": [
    "result['diff'] = result['train score'] - result['test score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:46:01.603112Z",
     "start_time": "2020-11-06T05:46:01.591977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model name  train score  test score  diff\n",
       "2       RandomForestClassifier         0.99        0.61  0.38\n",
       "3       DecisionTreeClassifier         0.99        0.49  0.51\n",
       "10             RidgeClassifier         0.88        0.73  0.15\n",
       "8                    LinearSVC         0.87        0.73  0.14\n",
       "11               SGDClassifier         0.87        0.73  0.13\n",
       "0           LogisticRegression         0.83        0.72  0.10\n",
       "1                MultinomialNB         0.76        0.68  0.08\n",
       "6               LGBMClassifier         0.73        0.65  0.08\n",
       "5   GradientBoostingClassifier         0.58        0.56  0.02\n",
       "9                      XgBoost         0.53        0.52  0.01\n",
       "4           AdaBoostClassifier         0.48        0.48 -0.00\n",
       "7         KNeighborsClassifier         0.46        0.27  0.19"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.round(2).sort_values(by='train score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경하여 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:22.860122Z",
     "start_time": "2020-11-06T05:46:01.604851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.701\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min-df 조정\n",
    "- min_df, max_df 는 아무런 결과의 차이를 가지고 오지 못했고,\n",
    "- sublinear_tf도 영향이 없었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:29.870122Z",
     "start_time": "2020-11-06T05:47:22.861854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.722\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', sublinear_tf = True)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:29.875128Z",
     "start_time": "2020-11-06T05:47:29.872613Z"
    }
   },
   "outputs": [],
   "source": [
    "# sublinear_tf : 높은 TF값들에 대해서 스무딩 처리, TF값에 대해 아웃라이어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:36.875029Z",
     "start_time": "2020-11-06T05:47:29.877679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.722\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=200000)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:36.882050Z",
     "start_time": "2020-11-06T05:47:36.877670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38415, 30690)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:36.888816Z",
     "start_time": "2020-11-06T05:47:36.884640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38415, 30690)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features = 20000개 일 때 정확도 0.722\n",
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:36.893703Z",
     "start_time": "2020-11-06T05:47:36.891254Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_features = 40000개 일 때 정확도 0.723\n",
    "# max_features = 80000개 일 때 정확도 0.723\n",
    "# max_features = 200000개 일 때 정확도 0.723\n",
    "# max_features 파라미터는 아무런 변화를 가지고 오지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV로 TfidfVectorizer parameter 조정\n",
    "- ngram_range=(1, 2) 가 최적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:58.691976Z",
     "start_time": "2020-11-06T05:47:36.896279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)), ('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
      "                                            fit_prior=True),\n",
      "                    n_jobs=None))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "#     'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:47:58.697515Z",
     "start_time": "2020-11-06T05:47:58.693837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6995704902421409"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tune.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV로 LogisticRegression C 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:21.829716Z",
     "start_time": "2020-11-06T05:47:58.699154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   17.4s remaining:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   18.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter: {'C': 5, 'random_state': 13}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.727\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정.\n",
    "params = { 'C': [0.01, 0.1, 1, 5, 10], 'random_state': [13]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
    "print('Logistic Regression best C parameter:', grid_cv_lr.best_params_)\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가\n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:21.845429Z",
     "start_time": "2020-11-06T05:48:21.840383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'random_state': 13}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:21.855842Z",
     "start_time": "2020-11-06T05:48:21.851046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7121957568658077"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T05:44:44.334574Z",
     "start_time": "2020-11-04T05:44:44.329602Z"
    }
   },
   "source": [
    "## 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:22.261672Z",
     "start_time": "2020-11-06T05:48:21.858511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB best parameters: {'alpha': 0.1, 'fit_prior': 'True'}\n",
      "MultinomialNB best accuracy score: 0.7180788754392816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "         'fit_prior': ['True', 'False']}\n",
    "clf = MultinomialNB()\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('MultinomialNB best parameters:', grid_cv.best_params_)\n",
    "print('MultinomialNB best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:22.294528Z",
     "start_time": "2020-11-06T05:48:22.263656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB train accuracy score 0.8374853572823115\n",
      "MultinomialNB test accuracy score 0.7308066083576288\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.1, fit_prior='True')\n",
    "clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = clf.predict(X_train_tfidf_vect)\n",
    "test_pred = clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('MultinomialNB train accuracy score', accuracy_score(y_train, train_pred))\n",
    "print('MultinomialNB test accuracy score', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:22.298958Z",
     "start_time": "2020-11-06T05:48:22.296294Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:22.429038Z",
     "start_time": "2020-11-06T05:48:22.300804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0175879 , 0.01331615, 0.01286483, 0.01333785, 0.01395202]),\n",
       " 'score_time': array([0.00237393, 0.00212479, 0.00227022, 0.00236893, 0.00264502]),\n",
       " 'test_score': array([0.72367565, 0.72302486, 0.72380581, 0.7271899 , 0.73070415]),\n",
       " 'train_score': array([0.8453729 , 0.84494989, 0.84511259, 0.84387609, 0.84442926])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:25.361485Z",
     "start_time": "2020-11-06T05:48:22.430644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8682806195496551\n",
      "LinearSVC test accuracy score: 0.7301992225461613\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC(C=1, loss='hinge', random_state=13)\n",
    "svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = svm_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:48.213567Z",
     "start_time": "2020-11-06T05:48:25.363254Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   1.8s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   1.8s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.4s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.2s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   19.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 1],\n",
       "                         'loss': ['squared_hinge', 'hinge'],\n",
       "                         'penalty': ['l1', 'l2'], 'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.001, 0.01, 1], \n",
    "    'loss': ['squared_hinge', 'hinge'], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'random_state': [13]\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(LinearSVC(), param_grid=params, refit=True, verbose=2)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:48.218731Z",
     "start_time": "2020-11-06T05:48:48.215531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Best parameters: {'C': 1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 13}\n",
      "LinearSVC Best accruacy score: 0.7220096316543018\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC Best parameters:', grid_cv.best_params_)\n",
    "print('LinearSVC Best accruacy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:51.417343Z",
     "start_time": "2020-11-06T05:48:48.220711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8682806195496551\n",
      "LinearSVC test accuracy score: 0.7301992225461613\n"
     ]
    }
   ],
   "source": [
    "svm_clf = LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)\n",
    "svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = svm_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, test_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:51.424913Z",
     "start_time": "2020-11-06T05:48:51.418946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False, False, False,  True],\n",
       "       ...,\n",
       "       [False, False, False, False, False],\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False,  True, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.decision_function(X_test_tfidf_vect) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:48:51.428689Z",
     "start_time": "2020-11-06T05:48:51.426570Z"
    }
   },
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:49:14.619700Z",
     "start_time": "2020-11-06T05:48:51.430409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.96901417, 2.654037  , 2.18455291, 2.05403781, 2.56171584,\n",
       "        2.57312608, 2.47893095, 2.5213201 , 1.95154691, 2.12115717]),\n",
       " 'score_time': array([0.00145912, 0.00115585, 0.001369  , 0.00162792, 0.00137615,\n",
       "        0.00139999, 0.00120807, 0.00129294, 0.00137401, 0.00132799]),\n",
       " 'test_score': array([0.7272254 , 0.7313899 , 0.72462259, 0.72280062, 0.72904737,\n",
       "        0.71908357, 0.72064567, 0.71960427, 0.74017183, 0.72533194]),\n",
       " 'train_score': array([0.87140254, 0.87137362, 0.87157609, 0.87151824, 0.8721835 ,\n",
       "        0.87175334, 0.87236073, 0.87192688, 0.86969977, 0.87262104])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "cross_validate(svm_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:49:15.026453Z",
     "start_time": "2020-11-06T05:49:14.621376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier train accuracy score: 0.8676818950930626\n",
      "SGDClassifier test accuracy score: 0.7329324586977648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=13, loss='modified_huber')\n",
    "sgd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = sgd_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = sgd_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('SGDClassifier train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('SGDClassifier test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:49:16.650824Z",
     "start_time": "2020-11-06T05:49:15.028762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72458675, 0.72146297, 0.71977092, 0.728101  , 0.72263439])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 검증\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_tfidf_vect, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T05:49:17.409376Z",
     "start_time": "2020-11-06T05:49:16.652987Z"
    }
   },
   "outputs": [],
   "source": [
    "# 오차 행렬\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_tfidf_vect, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:18:34.367591Z",
     "start_time": "2020-11-06T06:18:34.331571Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6675,  427,  796,  935,  396],\n",
       "       [ 557, 3305,  556,  566,  128],\n",
       "       [ 706,  236, 5636, 1062,  386],\n",
       "       [ 629,  240,  866, 8576,  196],\n",
       "       [ 784,  118,  778,  581, 3280]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:33.303222Z",
     "start_time": "2020-11-06T06:18:35.265498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:   57.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='modified_huber', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5, random_state=13,\n",
       "                                     shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                   1000.0],\n",
       "                         'loss': ['log', 'modified_huber', 'hinge',\n",
       "                                  'squared_hinge', 'perceptron'],\n",
       "                         'n_jobs': [-1], 'penalty': ['l2', 'elasticnet'],\n",
       "                         'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    'loss': ['log', 'modified_huber', 'hinge', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [13],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(sgd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:33.308095Z",
     "start_time": "2020-11-06T06:19:33.305259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 13}\n",
      "SGDClassifier best accuracy score: 0.7151373161525446\n"
     ]
    }
   ],
   "source": [
    "print('SGDClassifier best parameters:', grid_cv.best_params_)\n",
    "print('SGDClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:34.845322Z",
     "start_time": "2020-11-06T06:19:33.310774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.31299591, 0.28304791, 0.28077602, 0.2831018 , 0.32168198]),\n",
       " 'score_time': array([0.00261998, 0.00223494, 0.00217199, 0.00218797, 0.00200605]),\n",
       " 'test_score': array([0.72458675, 0.72146297, 0.71977092, 0.728101  , 0.72263439]),\n",
       " 'train_score': array([0.88419237, 0.88370428, 0.88428999, 0.88432253, 0.88484316])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(sgd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:55.486193Z",
     "start_time": "2020-11-06T06:19:34.847873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best parameters: {'alpha': 1.0, 'max_iter': 100, 'normalize': False, 'random_state': 13}\n",
      "RidgeClassifier best accuracy score: 0.71308082780164\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier()\n",
    "params = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [100, 300],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(rd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('RidgeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('RidgeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:55.928581Z",
     "start_time": "2020-11-06T06:19:55.488377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best train accuracy score: 0.8799427307041521\n",
      "RidgeClassifier best test accuracy score: 0.7144679300291545\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)\n",
    "rd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = rd_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = rd_clf.predict(X_test_tfidf_vect)\n",
    "print('RidgeClassifier best train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('RidgeClassifier best test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:20:00.030711Z",
     "start_time": "2020-11-06T06:19:55.930916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.38962412, 0.37851286, 0.36588693, 0.40881324, 0.4203701 ,\n",
       "        0.40804815, 0.37102795, 0.37114191, 0.41792321, 0.39581203]),\n",
       " 'score_time': array([0.00161481, 0.0022068 , 0.00217605, 0.00236201, 0.00239205,\n",
       "        0.00225687, 0.00222993, 0.00233579, 0.0026598 , 0.00258279]),\n",
       " 'test_score': array([0.70041645, 0.70640292, 0.7038001 , 0.70458095, 0.70458095,\n",
       "        0.70450404, 0.70320229, 0.70190055, 0.71465764, 0.69617287]),\n",
       " 'train_score': array([0.88519943, 0.88485234, 0.88502589, 0.88473664, 0.88531513,\n",
       "        0.88534737, 0.88413259, 0.88471105, 0.88404581, 0.88581015])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(rd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:21:42.560845Z",
     "start_time": "2020-11-06T06:20:00.033395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best parameters: {'C': 1.0, 'max_iter': 200}\n",
      "LogisticRegression best accuracy score: 0.7113627489262007\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 0.5, 1.0],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LogisticRegression best parameters:', grid_cv.best_params_)\n",
    "print('LogisticRegression best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:21:54.234814Z",
     "start_time": "2020-11-06T06:21:42.566690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 0.8322530261616556\n",
      "LogisticRegression test accuracy score: 0.722424684159378\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=1.0, max_iter=500)\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LogisticRegression train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LogisticRegression test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:23:46.400391Z",
     "start_time": "2020-11-06T06:21:54.238384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best parameters: {'boosting_type': 'dart', 'learning_rate': 0.01, 'max_bin': 255, 'n_estimators': 8, 'num_leaves': 8, 'objective': 'binary', 'random_state': 13, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "LGBMClassifier best accuracy score: 0.34457894051802684\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8],\n",
    "    'num_leaves': [6,8], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [13],\n",
    "#     'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "#     'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LGBMClassifier best parameters:', grid_cv.best_params_)\n",
    "print('LGBMClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:23:49.397597Z",
     "start_time": "2020-11-06T06:23:46.402168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best accuracy score: 0.3485787172011662\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(boosting_type='dart', learning_rate=0.01, max_bin=510, n_estimators=8, num_leaves=8,\n",
    "                        objective='binary', random_state=13, reg_alpha=1, reg_lambda=1)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "print('LGBMClassifier best accuracy score:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:24:25.135664Z",
     "start_time": "2020-11-06T06:23:49.399401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier train accuracy score: 0.729975270076793\n",
      "LGBMClassifier test accuracy score: 0.6499028182701652\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(random_state=13)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = lgb_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LGBMClassifier train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LGBMClassifier test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:26:38.116827Z",
     "start_time": "2020-11-06T06:24:25.137687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([21.22280693, 20.44541788, 20.26144385, 19.98406816, 20.01709628]),\n",
       " 'score_time': array([1.21222615, 1.21647286, 1.25959206, 1.20136285, 1.26162386]),\n",
       " 'test_score': array([0.64388911, 0.63607966, 0.64011454, 0.63881296, 0.64792399]),\n",
       " 'train_score': array([0.73815567, 0.73861122, 0.73796043, 0.74206039, 0.74036835])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(lgb_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:26:57.148725Z",
     "start_time": "2020-11-06T06:26:38.118718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier train score : 0.9919822985812834\n",
      "DecisionTreeClassifier test score : 0.4842687074829932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = dt_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = dt_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('DecisionTreeClassifier train score :', accuracy_score(y_train, train_pred))\n",
    "print('DecisionTreeClassifier test score :', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:27:23.785251Z",
     "start_time": "2020-11-06T06:26:57.149870Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier best parameters: {'max_depth': 120, 'min_samples_leaf': 32, 'min_samples_split': 16, 'random_state': 13}\n",
      "DecisionTreeClassifier best accuracy score: 0.4535207601197449\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [5, 10, 20, 120],\n",
    "    'min_samples_split': [16, 24],\n",
    "    'min_samples_leaf': [16, 32],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, verbose=1, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "print('DecisionTreeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('DecisionTreeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:27:23.821258Z",
     "start_time": "2020-11-06T06:27:23.787781Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-65bd78ae6ec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# CountVectorizer로 단어 갯수 카운트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mcv_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "abc = pd.merge(X_test, y_test, left_index = True, right_index=True)\n",
    "abc['pred'] = pred\n",
    "\n",
    "# 예측이 틀린 결과 -> 데이터 프레임 화\n",
    "error_df = abc[abc['author'] != abc['pred']]\n",
    "\n",
    "# CountVectorizer로 단어 갯수 카운트\n",
    "cv = CountVectorizer(stop_words='english')   \n",
    "cv_fit=cv.fit_transform(error_df['text'])    \n",
    "word_list = cv.get_feature_names();    \n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "di = dict(zip(word_list,count_list))\n",
    "\n",
    "# 예측이 틀린 결과 중 가장 많이 나온 단어 20개 정렬\n",
    "pd.DataFrame(list(di.items())).sort_values(by=1, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:27:23.822943Z",
     "start_time": "2020-11-06T06:18:49.485Z"
    }
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cb = CatBoostClassifier(silent=True, random_state=13, n_estimators=300).fit(X_train_tfidf_vect, y_train)\n",
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))\n",
    "# accuracy_score(y_test, cb.predict(X_test_tfidf_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:27:23.824189Z",
     "start_time": "2020-11-06T06:18:50.474Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
