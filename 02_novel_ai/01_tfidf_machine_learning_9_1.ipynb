{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:29:57.758407Z",
     "start_time": "2020-11-06T06:29:56.866346Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:29:58.016971Z",
     "start_time": "2020-11-06T06:29:57.760885Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "\n",
    "train = pd.read_csv('./open/train.csv', encoding='utf-8')\n",
    "test_x = pd.read_csv('./open/test_x.csv', encoding='utf-8')\n",
    "submission = pd.read_csv('./open/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:29:58.022416Z",
     "start_time": "2020-11-06T06:29:58.019433Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.loc[:, 'text']\n",
    "y = train.loc[:, 'author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:29:58.075225Z",
     "start_time": "2020-11-06T06:29:58.024227Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터라이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:30:00.621873Z",
     "start_time": "2020-11-06T06:29:58.077492Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 모델들 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:30:01.160376Z",
     "start_time": "2020-11-06T06:30:00.623646Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(random_state=13)))\n",
    "models.append(('MultinomialNB', MultinomialNB()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state=13, n_jobs=-1)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=13)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=13)))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state=13)))\n",
    "models.append(('LGBMClassifier', LGBMClassifier(random_state=13)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)))\n",
    "models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', random_state=13)))\n",
    "models.append(('XgBoost', XGBClassifier(learning_rate=0.1, max_depth=3, random_state=13, n_jobs=-1)))\n",
    "models.append(('RidgeClassifier', RidgeClassifier(random_state=13)))\n",
    "models.append(('SGDClassifier', SGDClassifier(random_state=13, loss='modified_huber')))\n",
    "# models.append(('RidgeClassifierCV', RidgeClassifierCV(cv=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:30:01.175223Z",
     "start_time": "2020-11-06T06:30:01.164580Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=13, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False)),\n",
       " ('MultinomialNB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('RandomForestClassifier',\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=13, verbose=0,\n",
       "                         warm_start=False)),\n",
       " ('DecisionTreeClassifier',\n",
       "  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=13, splitter='best')),\n",
       " ('AdaBoostClassifier',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                     n_estimators=50, random_state=13)),\n",
       " ('GradientBoostingClassifier',\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=13, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)),\n",
       " ('LGBMClassifier',\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=13, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
       " ('KNeighborsClassifier',\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                       weights='uniform')),\n",
       " ('LinearSVC',\n",
       "  LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "            penalty='l2', random_state=13, tol=0.0001, verbose=0)),\n",
       " ('XgBoost',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.1, max_delta_step=None, max_depth=3,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                objective='binary:logistic', random_state=13, reg_alpha=None,\n",
       "                reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                tree_method=None, validate_parameters=None, verbosity=None)),\n",
       " ('RidgeClassifier',\n",
       "  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                  max_iter=None, normalize=False, random_state=13, solver='auto',\n",
       "                  tol=0.001)),\n",
       " ('SGDClassifier',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "                max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "                power_t=0.5, random_state=13, shuffle=True, tol=0.001,\n",
       "                validation_fraction=0.1, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:35:41.222557Z",
     "start_time": "2020-11-06T06:30:01.178026Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:35:41.247735Z",
     "start_time": "2020-11-06T06:35:41.225321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.991152</td>\n",
       "      <td>0.619716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.991152</td>\n",
       "      <td>0.489431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.873135</td>\n",
       "      <td>0.738520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.862445</td>\n",
       "      <td>0.735241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.851613</td>\n",
       "      <td>0.738338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820737</td>\n",
       "      <td>0.727223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.760645</td>\n",
       "      <td>0.685860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.723573</td>\n",
       "      <td>0.657799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.578972</td>\n",
       "      <td>0.563229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.527222</td>\n",
       "      <td>0.513484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.481910</td>\n",
       "      <td>0.480321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.467636</td>\n",
       "      <td>0.283892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model name  train score  test score\n",
       "0       RandomForestClassifier     0.991152    0.619716\n",
       "1       DecisionTreeClassifier     0.991152    0.489431\n",
       "2              RidgeClassifier     0.873135    0.738520\n",
       "3                    LinearSVC     0.862445    0.735241\n",
       "4                SGDClassifier     0.851613    0.738338\n",
       "5           LogisticRegression     0.820737    0.727223\n",
       "6                MultinomialNB     0.760645    0.685860\n",
       "7               LGBMClassifier     0.723573    0.657799\n",
       "8   GradientBoostingClassifier     0.578972    0.563229\n",
       "9                      XgBoost     0.527222    0.513484\n",
       "10          AdaBoostClassifier     0.481910    0.480321\n",
       "11        KNeighborsClassifier     0.467636    0.283892"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score}) \n",
    "result.sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:35:41.253484Z",
     "start_time": "2020-11-06T06:35:41.249524Z"
    }
   },
   "outputs": [],
   "source": [
    "result['diff'] = result['train score'] - result['test score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:35:41.266121Z",
     "start_time": "2020-11-06T06:35:41.255300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model name  train score  test score  diff\n",
       "2       RandomForestClassifier         0.99        0.62  0.37\n",
       "3       DecisionTreeClassifier         0.99        0.49  0.50\n",
       "10             RidgeClassifier         0.87        0.74  0.13\n",
       "8                    LinearSVC         0.86        0.74  0.13\n",
       "11               SGDClassifier         0.85        0.74  0.11\n",
       "0           LogisticRegression         0.82        0.73  0.09\n",
       "1                MultinomialNB         0.76        0.69  0.07\n",
       "6               LGBMClassifier         0.72        0.66  0.07\n",
       "5   GradientBoostingClassifier         0.58        0.56  0.02\n",
       "9                      XgBoost         0.53        0.51  0.01\n",
       "4           AdaBoostClassifier         0.48        0.48  0.00\n",
       "7         KNeighborsClassifier         0.47        0.28  0.18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.round(2).sort_values(by='train score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경하여 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:27.284328Z",
     "start_time": "2020-11-06T06:35:41.268016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.713\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min-df 조정\n",
    "- min_df, max_df 는 아무런 결과의 차이를 가지고 오지 못했고,\n",
    "- sublinear_tf도 영향이 없었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:34.996279Z",
     "start_time": "2020-11-06T06:37:27.286229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.732\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', sublinear_tf = True)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:35.001005Z",
     "start_time": "2020-11-06T06:37:34.998545Z"
    }
   },
   "outputs": [],
   "source": [
    "# sublinear_tf : 높은 TF값들에 대해서 스무딩 처리, TF값에 대해 아웃라이어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:42.801776Z",
     "start_time": "2020-11-06T06:37:35.003460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.727\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=200000)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:42.807965Z",
     "start_time": "2020-11-06T06:37:42.804002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49391, 33374)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:42.814299Z",
     "start_time": "2020-11-06T06:37:42.810269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49391, 33374)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features = 20000개 일 때 정확도 0.722\n",
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:37:42.818785Z",
     "start_time": "2020-11-06T06:37:42.816539Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_features = 40000개 일 때 정확도 0.723\n",
    "# max_features = 80000개 일 때 정확도 0.723\n",
    "# max_features = 200000개 일 때 정확도 0.723\n",
    "# max_features 파라미터는 아무런 변화를 가지고 오지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV로 TfidfVectorizer parameter 조정\n",
    "- ngram_range=(1, 2) 가 최적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:12.156796Z",
     "start_time": "2020-11-06T06:37:42.821231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)), ('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
      "                                            fit_prior=True),\n",
      "                    n_jobs=None))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "#     'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:12.163421Z",
     "start_time": "2020-11-06T06:38:12.159409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7143406901417901"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tune.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV로 LogisticRegression C 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:37.723077Z",
     "start_time": "2020-11-06T06:38:12.165234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   18.7s remaining:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter: {'C': 5, 'random_state': 13}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.730\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정.\n",
    "params = { 'C': [0.01, 0.1, 1, 5, 10], 'random_state': [13]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
    "print('Logistic Regression best C parameter:', grid_cv_lr.best_params_)\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가\n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:37.738375Z",
     "start_time": "2020-11-06T06:38:37.733596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'random_state': 13}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:37.748647Z",
     "start_time": "2020-11-06T06:38:37.744231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7228239915381117"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T05:44:44.334574Z",
     "start_time": "2020-11-04T05:44:44.329602Z"
    }
   },
   "source": [
    "## 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:38.288019Z",
     "start_time": "2020-11-06T06:38:37.751192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB best parameters: {'alpha': 0.1, 'fit_prior': 'True'}\n",
      "MultinomialNB best accuracy score: 0.7284525797372168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "         'fit_prior': ['True', 'False']}\n",
    "clf = MultinomialNB()\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('MultinomialNB best parameters:', grid_cv.best_params_)\n",
    "print('MultinomialNB best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:38.326646Z",
     "start_time": "2020-11-06T06:38:38.290046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB train accuracy score 0.8318722034378733\n",
      "MultinomialNB test accuracy score 0.7299562682215743\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=0.1, fit_prior='True')\n",
    "clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = clf.predict(X_train_tfidf_vect)\n",
    "test_pred = clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('MultinomialNB train accuracy score', accuracy_score(y_train, train_pred))\n",
    "print('MultinomialNB test accuracy score', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:38.331009Z",
     "start_time": "2020-11-06T06:38:38.328508Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:38.534512Z",
     "start_time": "2020-11-06T06:38:38.332841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02710795, 0.02037978, 0.02053595, 0.02378201, 0.01931071]),\n",
       " 'score_time': array([0.004143  , 0.00379491, 0.00415301, 0.00355124, 0.00343227]),\n",
       " 'test_score': array([0.73134933, 0.73334683, 0.73081595, 0.73172707, 0.73850982]),\n",
       " 'train_score': array([0.83734055, 0.83721813, 0.83802799, 0.83820515, 0.83820515])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:38:42.041701Z",
     "start_time": "2020-11-06T06:38:38.536279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8624445749225568\n",
      "LinearSVC test accuracy score: 0.735240524781341\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_clf = LinearSVC(C=1, loss='hinge', random_state=13)\n",
    "svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = svm_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:11.373765Z",
     "start_time": "2020-11-06T06:38:42.043354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.9s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.3s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.7s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.9s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.4s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   26.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 1],\n",
       "                         'loss': ['squared_hinge', 'hinge'],\n",
       "                         'penalty': ['l1', 'l2'], 'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.001, 0.01, 1], \n",
    "    'loss': ['squared_hinge', 'hinge'], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'random_state': [13]\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(LinearSVC(), param_grid=params, refit=True, verbose=2)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:11.379499Z",
     "start_time": "2020-11-06T06:39:11.375899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Best parameters: {'C': 1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 13}\n",
      "LinearSVC Best accruacy score: 0.7321171516511974\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC Best parameters:', grid_cv.best_params_)\n",
    "print('LinearSVC Best accruacy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:14.820552Z",
     "start_time": "2020-11-06T06:39:11.381646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8624445749225568\n",
      "LinearSVC test accuracy score: 0.735240524781341\n"
     ]
    }
   ],
   "source": [
    "svm_clf = LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)\n",
    "svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = svm_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, test_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:14.827017Z",
     "start_time": "2020-11-06T06:39:14.822473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False, False,  True],\n",
       "       ...,\n",
       "       [False,  True, False, False, False],\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False, False, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.decision_function(X_test_tfidf_vect) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:14.830964Z",
     "start_time": "2020-11-06T06:39:14.828364Z"
    }
   },
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:45.142857Z",
     "start_time": "2020-11-06T06:39:14.832651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.58547807, 3.04706788, 3.0142498 , 3.01534319, 2.90946698,\n",
       "        3.13088226, 2.75170183, 2.85349894, 3.11283088, 2.74897099]),\n",
       " 'score_time': array([0.0013361 , 0.00157118, 0.00136089, 0.0016489 , 0.00151896,\n",
       "        0.00181293, 0.00170207, 0.00189805, 0.00155282, 0.00157118]),\n",
       " 'test_score': array([0.73238866, 0.74002835, 0.73780117, 0.73780117, 0.73658635,\n",
       "        0.73537153, 0.72909496, 0.74670986, 0.74569751, 0.73699129]),\n",
       " 'train_score': array([0.86394007, 0.86484298, 0.86477549, 0.86430307, 0.86378566,\n",
       "        0.86547287, 0.864708  , 0.86416809, 0.8641231 , 0.86455053])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "cross_validate(svm_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:45.699815Z",
     "start_time": "2020-11-06T06:39:45.144509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier train accuracy score: 0.851612641979308\n",
      "SGDClassifier test accuracy score: 0.7383381924198251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=13, loss='modified_huber')\n",
    "sgd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = sgd_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = sgd_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('SGDClassifier train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('SGDClassifier test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:47.516774Z",
     "start_time": "2020-11-06T06:39:45.701655Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73580322, 0.73223325, 0.73213201, 0.73658635, 0.73466289])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 검증\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_tfidf_vect, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:48.445740Z",
     "start_time": "2020-11-06T06:39:47.518518Z"
    }
   },
   "outputs": [],
   "source": [
    "# 오차 행렬\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_tfidf_vect, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:39:48.486373Z",
     "start_time": "2020-11-06T06:39:48.447440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8716,   494,   946,  1256,   416],\n",
       "       [  707,  4309,   671,   742,   133],\n",
       "       [  816,   270,  7398,  1403,   455],\n",
       "       [  717,   257,  1019, 11362,   229],\n",
       "       [ 1019,   162,   933,   744,  4217]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:02.417942Z",
     "start_time": "2020-11-06T06:39:48.488277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='modified_huber', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5, random_state=13,\n",
       "                                     shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                   1000.0],\n",
       "                         'loss': ['log', 'modified_huber', 'hinge',\n",
       "                                  'squared_hinge', 'perceptron'],\n",
       "                         'n_jobs': [-1], 'penalty': ['l2', 'elasticnet'],\n",
       "                         'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    'loss': ['log', 'modified_huber', 'hinge', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [13],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(sgd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:02.422832Z",
     "start_time": "2020-11-06T06:41:02.419887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 13}\n",
      "SGDClassifier best accuracy score: 0.7289182680184704\n"
     ]
    }
   ],
   "source": [
    "print('SGDClassifier best parameters:', grid_cv.best_params_)\n",
    "print('SGDClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:04.285090Z",
     "start_time": "2020-11-06T06:41:02.424713Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.37795401, 0.35158992, 0.348876  , 0.35236621, 0.35750175]),\n",
       " 'score_time': array([0.002918  , 0.00288606, 0.0029521 , 0.00299501, 0.00299311]),\n",
       " 'test_score': array([0.73580322, 0.73223325, 0.73213201, 0.73658635, 0.73466289]),\n",
       " 'train_score': array([0.86740737, 0.86571508, 0.86571508, 0.86910637, 0.86677802])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(sgd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:29.809655Z",
     "start_time": "2020-11-06T06:41:04.286968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   24.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best parameters: {'alpha': 1.0, 'max_iter': 100, 'normalize': False, 'random_state': 13}\n",
      "RidgeClassifier best accuracy score: 0.7253345810488326\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier()\n",
    "params = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [100, 300],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(rd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('RidgeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('RidgeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:30.309331Z",
     "start_time": "2020-11-06T06:41:29.812151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best train accuracy score: 0.870118037699176\n",
      "RidgeClassifier best test accuracy score: 0.7164723032069971\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)\n",
    "rd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = rd_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = rd_clf.predict(X_test_tfidf_vect)\n",
    "print('RidgeClassifier best train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('RidgeClassifier best test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:41:34.854326Z",
     "start_time": "2020-11-06T06:41:30.311751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.43895602, 0.42724109, 0.4216671 , 0.43673015, 0.44635272,\n",
       "        0.44482088, 0.43808293, 0.43241715, 0.41559196, 0.44209218]),\n",
       " 'score_time': array([0.00256014, 0.00260401, 0.00264502, 0.00259781, 0.00241327,\n",
       "        0.00259304, 0.00259614, 0.00264502, 0.00266504, 0.00250793]),\n",
       " 'test_score': array([0.71417004, 0.72059121, 0.71633934, 0.7159344 , 0.72160356,\n",
       "        0.71512452, 0.71573193, 0.7254505 , 0.72707026, 0.71917392]),\n",
       " 'train_score': array([0.87491845, 0.87505624, 0.87555116, 0.87476379, 0.8741114 ,\n",
       "        0.87507874, 0.87519122, 0.87462881, 0.87395393, 0.87498875])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(rd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:43:40.816262Z",
     "start_time": "2020-11-06T06:41:34.856445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best parameters: {'C': 1.0, 'max_iter': 500}\n",
      "LogisticRegression best accuracy score: 0.7227024706992676\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 0.5, 1.0],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LogisticRegression best parameters:', grid_cv.best_params_)\n",
    "print('LogisticRegression best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:43:57.065672Z",
     "start_time": "2020-11-06T06:43:40.818759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 0.8295438440201656\n",
      "LogisticRegression test accuracy score: 0.7279518950437318\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=1.0, max_iter=500)\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LogisticRegression train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LogisticRegression test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:46:45.494764Z",
     "start_time": "2020-11-06T06:43:57.068153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best parameters: {'boosting_type': 'dart', 'learning_rate': 0.01, 'max_bin': 510, 'n_estimators': 8, 'num_leaves': 8, 'objective': 'binary', 'random_state': 13, 'reg_alpha': 1, 'reg_lambda': 1.2}\n",
      "LGBMClassifier best accuracy score: 0.34526535608090125\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8],\n",
    "    'num_leaves': [6,8], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [13],\n",
    "#     'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "#     'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LGBMClassifier best parameters:', grid_cv.best_params_)\n",
    "print('LGBMClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:46:50.131228Z",
     "start_time": "2020-11-06T06:46:45.496425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best accuracy score: 0.3504008746355685\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(boosting_type='dart', learning_rate=0.01, max_bin=510, n_estimators=8, num_leaves=8,\n",
    "                        objective='binary', random_state=13, reg_alpha=1, reg_lambda=1)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "print('LGBMClassifier best accuracy score:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:47:38.652322Z",
     "start_time": "2020-11-06T06:46:50.132831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier train accuracy score: 0.7235731206090178\n",
      "LGBMClassifier test accuracy score: 0.657798833819242\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(random_state=13)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = lgb_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LGBMClassifier train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LGBMClassifier test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:50:41.360663Z",
     "start_time": "2020-11-06T06:47:38.654136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([27.39625287, 28.24214578, 27.49334121, 27.31333208, 31.52967191]),\n",
       " 'score_time': array([1.56889009, 1.65437198, 1.6652658 , 1.57324076, 1.64751101]),\n",
       " 'test_score': array([0.65451969, 0.65104272, 0.64547479, 0.64932173, 0.65883782]),\n",
       " 'train_score': array([0.7306641 , 0.73069623, 0.73153139, 0.73067092, 0.73170855])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(lgb_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:51:08.499900Z",
     "start_time": "2020-11-06T06:50:41.362615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier train score : 0.9911522342127108\n",
      "DecisionTreeClassifier test score : 0.49034256559766765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = dt_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = dt_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('DecisionTreeClassifier train score :', accuracy_score(y_train, train_pred))\n",
    "print('DecisionTreeClassifier test score :', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:51:48.860526Z",
     "start_time": "2020-11-06T06:51:08.501570Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   35.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier best parameters: {'max_depth': 120, 'min_samples_leaf': 32, 'min_samples_split': 16, 'random_state': 13}\n",
      "DecisionTreeClassifier best accuracy score: 0.46275632254962107\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [5, 10, 20, 120],\n",
    "    'min_samples_split': [16, 24],\n",
    "    'min_samples_leaf': [16, 32],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, verbose=1, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "print('DecisionTreeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('DecisionTreeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:55:08.580945Z",
     "start_time": "2020-11-06T06:55:08.019863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>odin</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>said</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5974</th>\n",
       "      <td>man</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>mr</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>time</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9877</th>\n",
       "      <td>think</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>know</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>little</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>did</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>come</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>good</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>sir</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>like</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8487</th>\n",
       "      <td>say</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>cried</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>hand</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8713</th>\n",
       "      <td>shall</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>great</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>house</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>came</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "6653    odin  2136\n",
       "8420    said   941\n",
       "5974     man   347\n",
       "6354      mr   292\n",
       "9953    time   268\n",
       "9877   think   252\n",
       "5519    know   252\n",
       "5774  little   247\n",
       "2788     did   231\n",
       "1916    come   227\n",
       "4308    good   225\n",
       "8914     sir   224\n",
       "5725    like   218\n",
       "8487     say   205\n",
       "2351   cried   178\n",
       "4514    hand   170\n",
       "8713   shall   170\n",
       "4373   great   169\n",
       "4830   house   165\n",
       "1436    came   163"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "abc = pd.merge(X_test, y_test, left_index = True, right_index=True)\n",
    "abc['pred'] = pred\n",
    "\n",
    "# 예측이 틀린 결과 -> 데이터 프레임 화\n",
    "error_df = abc[abc['author'] != abc['pred']]\n",
    "\n",
    "# CountVectorizer로 단어 갯수 카운트\n",
    "cv = CountVectorizer(stop_words='english')   \n",
    "cv_fit=cv.fit_transform(error_df['text'])    \n",
    "word_list = cv.get_feature_names();    \n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "di = dict(zip(word_list,count_list))\n",
    "\n",
    "# 예측이 틀린 결과 중 가장 많이 나온 단어 20개 정렬\n",
    "pd.DataFrame(list(di.items())).sort_values(by=1, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:51:49.181661Z",
     "start_time": "2020-11-06T06:29:56.947Z"
    }
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cb = CatBoostClassifier(silent=True, random_state=13, n_estimators=300).fit(X_train_tfidf_vect, y_train)\n",
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))\n",
    "# accuracy_score(y_test, cb.predict(X_test_tfidf_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:51:49.182650Z",
     "start_time": "2020-11-06T06:29:56.949Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
