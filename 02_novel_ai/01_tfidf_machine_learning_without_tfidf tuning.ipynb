{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:09.731501Z",
     "start_time": "2020-11-08T01:50:08.966892Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:10.002266Z",
     "start_time": "2020-11-08T01:50:09.733952Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "\n",
    "train = pd.read_csv('./open/train.csv', encoding='utf-8')\n",
    "test_x = pd.read_csv('./open/test_x.csv', encoding='utf-8')\n",
    "submission = pd.read_csv('./open/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:10.007453Z",
     "start_time": "2020-11-08T01:50:10.004432Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.loc[:, 'text']\n",
    "y = train.loc[:, 'author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:10.062377Z",
     "start_time": "2020-11-08T01:50:10.009140Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터라이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:12.418430Z",
     "start_time": "2020-11-08T01:50:10.064635Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 모델들 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:12.910253Z",
     "start_time": "2020-11-08T01:50:12.420090Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(random_state=13)))\n",
    "models.append(('MultinomialNB', MultinomialNB()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state=13, n_jobs=-1)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=13)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=13)))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state=13)))\n",
    "models.append(('LGBMClassifier', LGBMClassifier(random_state=13)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)))\n",
    "models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', random_state=13)))\n",
    "models.append(('XgBoost', XGBClassifier(learning_rate=0.1, max_depth=3, random_state=13, n_jobs=-1)))\n",
    "models.append(('RidgeClassifier', RidgeClassifier(random_state=13)))\n",
    "models.append(('SGDClassifier', SGDClassifier(random_state=13, loss='modified_huber')))\n",
    "# models.append(('RidgeClassifierCV', RidgeClassifierCV(cv=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:50:12.923464Z",
     "start_time": "2020-11-08T01:50:12.913666Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=13, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False)),\n",
       " ('MultinomialNB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)),\n",
       " ('RandomForestClassifier',\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=13, verbose=0,\n",
       "                         warm_start=False)),\n",
       " ('DecisionTreeClassifier',\n",
       "  DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                         max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                         random_state=13, splitter='best')),\n",
       " ('AdaBoostClassifier',\n",
       "  AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                     n_estimators=50, random_state=13)),\n",
       " ('GradientBoostingClassifier',\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=13, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)),\n",
       " ('LGBMClassifier',\n",
       "  LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=13, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0)),\n",
       " ('KNeighborsClassifier',\n",
       "  KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                       metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                       weights='uniform')),\n",
       " ('LinearSVC',\n",
       "  LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=1, loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "            penalty='l2', random_state=13, tol=0.0001, verbose=0)),\n",
       " ('XgBoost',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.1, max_delta_step=None, max_depth=3,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                objective='binary:logistic', random_state=13, reg_alpha=None,\n",
       "                reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "                tree_method=None, validate_parameters=None, verbosity=None)),\n",
       " ('RidgeClassifier',\n",
       "  RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
       "                  max_iter=None, normalize=False, random_state=13, solver='auto',\n",
       "                  tol=0.001)),\n",
       " ('SGDClassifier',\n",
       "  SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
       "                max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "                power_t=0.5, random_state=13, shuffle=True, tol=0.001,\n",
       "                validation_fraction=0.1, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:55:04.240649Z",
     "start_time": "2020-11-08T01:50:12.926147Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:55:04.260676Z",
     "start_time": "2020-11-08T01:55:04.242545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XgBoost</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model name  train score  test score  diff\n",
       "0       RandomForestClassifier         0.99        0.62  0.37\n",
       "1       DecisionTreeClassifier         0.99        0.49  0.50\n",
       "2              RidgeClassifier         0.88        0.73  0.15\n",
       "3                    LinearSVC         0.87        0.73  0.13\n",
       "4                SGDClassifier         0.86        0.73  0.13\n",
       "5           LogisticRegression         0.83        0.72  0.10\n",
       "6                MultinomialNB         0.76        0.69  0.07\n",
       "7               LGBMClassifier         0.73        0.65  0.07\n",
       "8   GradientBoostingClassifier         0.58        0.56  0.02\n",
       "9                      XgBoost         0.53        0.52  0.01\n",
       "10          AdaBoostClassifier         0.48        0.48 -0.00\n",
       "11        KNeighborsClassifier         0.45        0.27  0.18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score})\n",
    "result['diff'] = result['train score'] - result['test score']\n",
    "result.round(2).sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### stop words 필터링을 추가하고 ngram을 기본 (1,1)에서 (1,2)로 변경하여 피처 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:41.861591Z",
     "start_time": "2020-11-08T01:55:04.281459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.708\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min-df 조정\n",
    "- min_df, max_df 는 아무런 결과의 차이를 가지고 오지 못했고,\n",
    "- sublinear_tf도 영향이 없었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:50.266709Z",
     "start_time": "2020-11-08T01:56:41.864220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.724\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', sublinear_tf = True)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:50.272114Z",
     "start_time": "2020-11-08T01:56:50.269367Z"
    }
   },
   "outputs": [],
   "source": [
    "# sublinear_tf : 높은 TF값들에 대해서 스무딩 처리, TF값에 대해 아웃라이어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:59.378880Z",
     "start_time": "2020-11-08T01:56:50.274642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.723\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_features=200000)\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test ,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:59.387998Z",
     "start_time": "2020-11-08T01:56:59.382126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43903, 32118)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:59.395067Z",
     "start_time": "2020-11-08T01:56:59.390649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43903, 32118)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features = 20000개 일 때 정확도 0.722\n",
    "X_train_tfidf_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:56:59.400275Z",
     "start_time": "2020-11-08T01:56:59.397530Z"
    }
   },
   "outputs": [],
   "source": [
    "# max_features = 40000개 일 때 정확도 0.723\n",
    "# max_features = 80000개 일 때 정확도 0.723\n",
    "# max_features = 200000개 일 때 정확도 0.723\n",
    "# max_features 파라미터는 아무런 변화를 가지고 오지 못함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV로 TfidfVectorizer parameter 조정\n",
    "- ngram_range=(1, 2) 가 최적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:57:31.099398Z",
     "start_time": "2020-11-08T01:56:59.403201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:   25.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)), ('clf', OneVsRestClassifier(estimator=MultinomialNB(alpha=0.01, class_prior=None,\n",
      "                                            fit_prior=True),\n",
      "                    n_jobs=None))]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters = {\n",
    "#     'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}\n",
    "\n",
    "grid_search_tune = GridSearchCV(pipeline, parameters, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:57:31.107937Z",
     "start_time": "2020-11-08T01:57:31.102626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048948827832544"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tune.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV로 LogisticRegression C 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.191589Z",
     "start_time": "2020-11-08T01:57:31.110618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:   24.1s remaining:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best C parameter: {'C': 5, 'random_state': 13}\n",
      "TF-IDF Vectorized Logistic Regression 의 예측 정확도는 0.726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 최적 C 값 도출 튜닝 수행. CV는 3 Fold셋으로 설정.\n",
    "params = { 'C': [0.01, 0.1, 1, 5, 10], 'random_state': [13]}\n",
    "grid_cv_lr = GridSearchCV(lr_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv_lr.fit(X_train_tfidf_vect, y_train)\n",
    "print('Logistic Regression best C parameter:', grid_cv_lr.best_params_)\n",
    "\n",
    "# 최적 C 값으로 학습된 grid_cv로 예측 수행하고 정확도 평가\n",
    "pred = grid_cv_lr.predict(X_test_tfidf_vect)\n",
    "print('TF-IDF Vectorized Logistic Regression 의 예측 정확도는 {0:.3f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.207970Z",
     "start_time": "2020-11-08T01:58:02.202946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 5, 'random_state': 13}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.217717Z",
     "start_time": "2020-11-08T01:58:02.213424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7178551750593618"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_lr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T05:44:44.334574Z",
     "start_time": "2020-11-04T05:44:44.329602Z"
    }
   },
   "source": [
    "## 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.678246Z",
     "start_time": "2020-11-08T01:58:02.220201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB best parameters: {'alpha': 0.1, 'fit_prior': 'True'}\n",
      "MultinomialNB best accuracy score: 0.7235268361870119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "         'fit_prior': ['True', 'False']}\n",
    "clf = MultinomialNB()\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('MultinomialNB best parameters:', grid_cv.best_params_)\n",
    "print('MultinomialNB best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.714451Z",
     "start_time": "2020-11-08T01:58:02.680413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB train accuracy score 0.8349087761656379\n",
      "MultinomialNB test accuracy score 0.731231778425656\n"
     ]
    }
   ],
   "source": [
    "mu_clf = MultinomialNB(alpha=0.1, fit_prior='True')\n",
    "mu_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "mu_train_pred = mu_clf.predict(X_train_tfidf_vect)\n",
    "mu_test_pred = mu_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('MultinomialNB train accuracy score', accuracy_score(y_train, mu_train_pred))\n",
    "print('MultinomialNB test accuracy score', accuracy_score(y_test, mu_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.718689Z",
     "start_time": "2020-11-08T01:58:02.716547Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:02.901319Z",
     "start_time": "2020-11-08T01:58:02.720252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02347112, 0.02090478, 0.01915121, 0.01864433, 0.01804709]),\n",
       " 'score_time': array([0.00352192, 0.00471091, 0.00376391, 0.0030489 , 0.00392294]),\n",
       " 'test_score': array([0.73271837, 0.73032684, 0.73157955, 0.73280182, 0.7308656 ]),\n",
       " 'train_score': array([0.84072661, 0.84160925, 0.84300438, 0.84110127, 0.84198389])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(mu_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:07.158886Z",
     "start_time": "2020-11-08T01:58:02.903916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8660228230417055\n",
      "LinearSVC test accuracy score: 0.7331450437317785\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_clf = LinearSVC(C=1, loss='hinge', random_state=13)\n",
    "svc_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "svc_train_pred = svc_clf.predict(X_train_tfidf_vect)\n",
    "svc_test_pred = svc_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, svc_train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:41.129369Z",
     "start_time": "2020-11-08T01:58:07.160746Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.1s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   1.2s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.9s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   0.9s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.2s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.5s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.7s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.2s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   30.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.01, 1],\n",
       "                         'loss': ['squared_hinge', 'hinge'],\n",
       "                         'penalty': ['l1', 'l2'], 'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.001, 0.01, 1], \n",
    "    'loss': ['squared_hinge', 'hinge'], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'random_state': [13]\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(LinearSVC(), param_grid=params, refit=True, verbose=2)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:41.133770Z",
     "start_time": "2020-11-08T01:58:41.131017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Best parameters: {'C': 1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 13}\n",
      "LinearSVC Best accruacy score: 0.7300185583960399\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC Best parameters:', grid_cv.best_params_)\n",
    "print('LinearSVC Best accruacy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:44.502138Z",
     "start_time": "2020-11-08T01:58:41.135467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8660228230417055\n",
      "LinearSVC test accuracy score: 0.7331450437317785\n"
     ]
    }
   ],
   "source": [
    "svc_svm_clf = LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)\n",
    "svc_svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "svc_train_pred = svc_svm_clf.predict(X_train_tfidf_vect)\n",
    "svc_test_pred = svc_svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, svc_train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, svc_test_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:44.509480Z",
     "start_time": "2020-11-08T01:58:44.503868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False, False, False,  True],\n",
       "       ...,\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False, False, False,  True]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_svm_clf.decision_function(X_test_tfidf_vect) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:58:44.513345Z",
     "start_time": "2020-11-08T01:58:44.511138Z"
    }
   },
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:59:14.142313Z",
     "start_time": "2020-11-08T01:58:44.515071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.01112199, 2.50579286, 3.23305893, 2.76333189, 2.923774  ,\n",
       "        3.14577007, 3.1926558 , 2.72132301, 3.21674228, 2.77025533]),\n",
       " 'score_time': array([0.0015521 , 0.00157309, 0.0016098 , 0.00181127, 0.0015738 ,\n",
       "        0.00156212, 0.00163913, 0.00179935, 0.00162673, 0.00146294]),\n",
       " 'test_score': array([0.73445684, 0.72102027, 0.74083352, 0.72642369, 0.73986333,\n",
       "        0.74350797, 0.7214123 , 0.738041  , 0.73302961, 0.73781321]),\n",
       " 'train_score': array([0.86862219, 0.86834379, 0.86874873, 0.86966315, 0.86842305,\n",
       "        0.86968846, 0.86865082, 0.8676385 , 0.86849898, 0.86829651])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "cross_validate(svc_svm_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:59:14.631497Z",
     "start_time": "2020-11-08T01:59:14.143864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier train accuracy score: 0.8592351319955356\n",
      "SGDClassifier test accuracy score: 0.7332361516034985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=13, loss='modified_huber')\n",
    "sgd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "sgd_train_pred = sgd_clf.predict(X_train_tfidf_vect)\n",
    "sgd_test_pred = sgd_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('SGDClassifier train accuracy score:', accuracy_score(y_train, sgd_train_pred))\n",
    "print('SGDClassifier test accuracy score:', accuracy_score(y_test, sgd_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:59:16.507633Z",
     "start_time": "2020-11-08T01:59:14.633289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73397107, 0.73727366, 0.72679649, 0.73405467, 0.73075171])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 검증\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_tfidf_vect, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:59:17.502809Z",
     "start_time": "2020-11-08T01:59:16.509906Z"
    }
   },
   "outputs": [],
   "source": [
    "# 오차 행렬\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_tfidf_vect, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T01:59:17.543583Z",
     "start_time": "2020-11-08T01:59:17.504541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7559,  471,  915, 1111,  456],\n",
       "       [ 606, 3830,  634,  635,  136],\n",
       "       [ 723,  237, 6604, 1223,  435],\n",
       "       [ 639,  238,  940, 9981,  236],\n",
       "       [ 835,  135,  870,  669, 3785]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:00:29.122335Z",
     "start_time": "2020-11-08T01:59:17.545513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                     class_weight=None, early_stopping=False,\n",
       "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                                     l1_ratio=0.15, learning_rate='optimal',\n",
       "                                     loss='modified_huber', max_iter=1000,\n",
       "                                     n_iter_no_change=5, n_jobs=None,\n",
       "                                     penalty='l2', power_t=0.5, random_state=13,\n",
       "                                     shuffle=True, tol=0.001,\n",
       "                                     validation_fraction=0.1, verbose=0,\n",
       "                                     warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                   1000.0],\n",
       "                         'loss': ['log', 'modified_huber', 'hinge',\n",
       "                                  'squared_hinge', 'perceptron'],\n",
       "                         'n_jobs': [-1], 'penalty': ['l2', 'elasticnet'],\n",
       "                         'random_state': [13]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    'loss': ['log', 'modified_huber', 'hinge', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [13],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(sgd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:00:29.126592Z",
     "start_time": "2020-11-08T02:00:29.123985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier best parameters: {'alpha': 0.0001, 'loss': 'modified_huber', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 13}\n",
      "SGDClassifier best accuracy score: 0.7233901899433525\n"
     ]
    }
   ],
   "source": [
    "print('SGDClassifier best parameters:', grid_cv.best_params_)\n",
    "print('SGDClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:00:31.629968Z",
     "start_time": "2020-11-08T02:00:29.128196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.50120807, 0.42848897, 0.54985309, 0.47018981, 0.46314192]),\n",
       " 'score_time': array([0.00359988, 0.00411582, 0.00498295, 0.00413322, 0.00345588]),\n",
       " 'test_score': array([0.73397107, 0.73727366, 0.72679649, 0.73405467, 0.73075171]),\n",
       " 'train_score': array([0.87383976, 0.87557656, 0.87660156, 0.87595023, 0.87572246])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(sgd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:01:01.040697Z",
     "start_time": "2020-11-08T02:00:31.632349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best parameters: {'alpha': 1.0, 'max_iter': 100, 'normalize': False, 'random_state': 13}\n",
      "RidgeClassifier best accuracy score: 0.7193358294665587\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier()\n",
    "params = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [100, 300],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(rd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('RidgeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('RidgeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:01:01.582023Z",
     "start_time": "2020-11-08T02:01:01.043590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best train accuracy score: 0.8744504931325877\n",
      "RidgeClassifier best test accuracy score: 0.7160167638483965\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)\n",
    "rd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "rd_train_pred = rd_clf.predict(X_train_tfidf_vect)\n",
    "rd_test_pred = rd_clf.predict(X_test_tfidf_vect)\n",
    "print('RidgeClassifier best train accuracy score:', accuracy_score(y_train, rd_train_pred))\n",
    "print('RidgeClassifier best test accuracy score:', accuracy_score(y_test, rd_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:01:06.674344Z",
     "start_time": "2020-11-08T02:01:01.585221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.46430492, 0.46808791, 0.45691228, 0.48221111, 0.54432106,\n",
       "        0.45497799, 0.51907086, 0.50296211, 0.4991529 , 0.48341298]),\n",
       " 'score_time': array([0.00313401, 0.00292993, 0.00259399, 0.00349116, 0.00264287,\n",
       "        0.00299501, 0.00276208, 0.00331402, 0.00330305, 0.00297499]),\n",
       " 'test_score': array([0.71509907, 0.69801867, 0.71805967, 0.70888383, 0.71799544,\n",
       "        0.7191344 , 0.70410023, 0.7166287 , 0.70523918, 0.71617312]),\n",
       " 'train_score': array([0.87975805, 0.87983397, 0.87866977, 0.87965986, 0.87958393,\n",
       "        0.87907777, 0.88006479, 0.87935616, 0.87973578, 0.87996356])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(rd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:03:12.544340Z",
     "start_time": "2020-11-08T02:01:06.676490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best parameters: {'C': 1.0, 'max_iter': 200}\n",
      "LogisticRegression best accuracy score: 0.718834740777808\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 0.5, 1.0],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LogisticRegression best parameters:', grid_cv.best_params_)\n",
    "print('LogisticRegression best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:03:27.442684Z",
     "start_time": "2020-11-08T02:03:12.547088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 0.8322438102179806\n",
      "LogisticRegression test accuracy score: 0.7260386297376094\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=1.0, max_iter=500)\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "lr_train_pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "lr_test_pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LogisticRegression train accuracy score:', accuracy_score(y_train, lr_train_pred))\n",
    "print('LogisticRegression test accuracy score:', accuracy_score(y_test, lr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:06:03.219456Z",
     "start_time": "2020-11-08T02:03:27.445381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best parameters: {'boosting_type': 'dart', 'learning_rate': 0.01, 'max_bin': 510, 'n_estimators': 8, 'num_leaves': 8, 'objective': 'binary', 'random_state': 13, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "LGBMClassifier best accuracy score: 0.34489685096134515\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01],\n",
    "    'n_estimators': [8],\n",
    "    'num_leaves': [6,8], # large num_leaves helps improve accuracy but might lead to over-fitting\n",
    "    'boosting_type' : ['dart'], # for better accuracy -> try dart\n",
    "    'objective' : ['binary'],\n",
    "    'max_bin':[255, 510], # large max_bin helps improve accuracy but might slow down training progress\n",
    "    'random_state' : [13],\n",
    "#     'colsample_bytree' : [0.64, 0.65, 0.66],\n",
    "#     'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LGBMClassifier best parameters:', grid_cv.best_params_)\n",
    "print('LGBMClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:06:07.576565Z",
     "start_time": "2020-11-08T02:06:03.221389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier best accuracy score: 0.3497631195335277\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(boosting_type='dart', learning_rate=0.01, max_bin=510, n_estimators=8, num_leaves=8,\n",
    "                        objective='binary', random_state=13, reg_alpha=1, reg_lambda=1)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "print('LGBMClassifier best accuracy score:', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:06:50.467871Z",
     "start_time": "2020-11-08T02:06:07.578390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier train accuracy score: 0.8592351319955356\n",
      "LGBMClassifier test accuracy score: 0.7332361516034985\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(random_state=13)\n",
    "lgb_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "lgb_train_pred = lgb_clf.predict(X_train_tfidf_vect)\n",
    "lgb_test_pred = lgb_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LGBMClassifier train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('LGBMClassifier test accuracy score:', accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:10:04.716843Z",
     "start_time": "2020-11-08T02:06:50.469618Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([32.22999191, 31.499861  , 28.85051799, 30.26241589, 29.88290715]),\n",
       " 'score_time': array([1.86452985, 1.96915913, 1.56499314, 1.56113005, 1.61052489]),\n",
       " 'test_score': array([0.6523175 , 0.64605398, 0.64149869, 0.64840547, 0.65056948]),\n",
       " 'train_score': array([0.73173509, 0.7339844 , 0.73506634, 0.73350796, 0.73564331])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(lgb_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:10:31.295034Z",
     "start_time": "2020-11-08T02:10:04.718833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier train score : 0.9914812199621894\n",
      "DecisionTreeClassifier test score : 0.49152696793002915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "dt_train_pred = dt_clf.predict(X_train_tfidf_vect)\n",
    "dt_test_pred = dt_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('DecisionTreeClassifier train score :', accuracy_score(y_train, dt_train_pred))\n",
    "print('DecisionTreeClassifier test score :', accuracy_score(y_test, dt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:09.050009Z",
     "start_time": "2020-11-08T02:10:31.296624Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   33.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier best parameters: {'max_depth': 120, 'min_samples_leaf': 32, 'min_samples_split': 16, 'random_state': 13}\n",
      "DecisionTreeClassifier best accuracy score: 0.4575086922764231\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [5, 10, 20, 120],\n",
    "    'min_samples_split': [16, 24],\n",
    "    'min_samples_leaf': [16, 32],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, verbose=1, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "print('DecisionTreeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('DecisionTreeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:14:21.792269Z",
     "start_time": "2020-11-08T02:14:21.610988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>odin</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>said</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>man</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>come</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>did</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>mr</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>think</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>cried</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>know</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>time</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>say</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>little</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5597</th>\n",
       "      <td>sir</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>good</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>like</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>asked</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>away</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>hand</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465</th>\n",
       "      <td>shall</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>don</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "4204    odin  1397\n",
       "5281    said   731\n",
       "3762     man   206\n",
       "1182    come   175\n",
       "1720     did   161\n",
       "4012      mr   161\n",
       "6227   think   158\n",
       "1458   cried   157\n",
       "3478    know   150\n",
       "6283    time   142\n",
       "5320     say   139\n",
       "3641  little   136\n",
       "5597     sir   132\n",
       "2719    good   129\n",
       "3610    like   124\n",
       "396    asked   119\n",
       "480     away    97\n",
       "2847    hand    96\n",
       "5465   shall    96\n",
       "1855     don    94"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "abc = pd.merge(X_test, y_test, left_index = True, right_index=True)\n",
    "abc['pred'] = sgd_test_pred\n",
    "\n",
    "# 예측이 틀린 결과 -> 데이터 프레임 화\n",
    "error_df = abc[abc['author'] != abc['pred']]\n",
    "\n",
    "# CountVectorizer로 단어 갯수 카운트\n",
    "cv = CountVectorizer(stop_words='english')   \n",
    "cv_fit=cv.fit_transform(error_df['text'])    \n",
    "word_list = cv.get_feature_names();    \n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "di = dict(zip(word_list,count_list))\n",
    "\n",
    "# 예측이 틀린 결과 중 가장 많이 나온 단어 20개 정렬\n",
    "pd.DataFrame(list(di.items())).sort_values(by=1, ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:09.884669Z",
     "start_time": "2020-11-08T02:11:09.883002Z"
    }
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cb = CatBoostClassifier(silent=True, random_state=13, n_estimators=300).fit(X_train_tfidf_vect, y_train)\n",
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))\n",
    "# accuracy_score(y_test, cb.predict(X_test_tfidf_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:09.887971Z",
     "start_time": "2020-11-08T02:11:09.886312Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:09.893413Z",
     "start_time": "2020-11-08T02:11:09.889443Z"
    }
   },
   "outputs": [],
   "source": [
    "t_models = []\n",
    "\n",
    "t_models.append(('MultinomialNB', MultinomialNB(alpha=0.5, fit_prior='True')))\n",
    "t_models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)))\n",
    "t_models.append(('SGDClassifier', SGDClassifier(alpha=0.0001, loss='modified_huber', n_jobs=-1, penalty='l2', random_state=13)))\n",
    "t_models.append(('RidgeClassifier', RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)))\n",
    "t_models.append(('LogisticRegression', LogisticRegression(C=1.0, max_iter=500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:29.186913Z",
     "start_time": "2020-11-08T02:11:09.895150Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in t_models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T02:11:29.210494Z",
     "start_time": "2020-11-08T02:11:29.189480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model name  train score  test score  diff\n",
       "0           LinearSVC         0.87        0.73  0.13\n",
       "1     RidgeClassifier         0.87        0.72  0.16\n",
       "2       SGDClassifier         0.86        0.73  0.13\n",
       "3  LogisticRegression         0.83        0.73  0.11\n",
       "4       MultinomialNB         0.80        0.72  0.08"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score})\n",
    "result['diff'] = result['train score'] - result['test score']\n",
    "result.round(2).sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
