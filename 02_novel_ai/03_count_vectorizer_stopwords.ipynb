{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:04.284128Z",
     "start_time": "2020-11-08T07:40:03.438010Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:04.540626Z",
     "start_time": "2020-11-08T07:40:04.286581Z"
    }
   },
   "outputs": [],
   "source": [
    "# 파일 불러오기\n",
    "\n",
    "train = pd.read_csv('./open/word.csv', encoding='utf-8')\n",
    "test_x = pd.read_csv('./open/test_x.csv', encoding='utf-8')\n",
    "submission = pd.read_csv('./open/sample_submission.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '//////',\n",
       " 'said',\n",
       " 'man',\n",
       " 'come',\n",
       " 'think',\n",
       " 'did',\n",
       " 'know',\n",
       " 'cried',\n",
       " 'mr',\n",
       " 'time',\n",
       " 'little',\n",
       " 'good',\n",
       " 'say',\n",
       " 'sir',\n",
       " 'like',\n",
       " 'asked',\n",
       " 'old',\n",
       " 'shall',\n",
       " 'thought',\n",
       " 'away',\n",
       " 'oh',\n",
       " 'came',\n",
       " 'don',\n",
       " 'face',\n",
       " 'great',\n",
       " 'hand',\n",
       " 'long',\n",
       " 'house',\n",
       " 'yes',\n",
       " 'eyes',\n",
       " 'dear',\n",
       " 'looked',\n",
       " 'way',\n",
       " 'quite',\n",
       " 'night',\n",
       " 'let',\n",
       " 'young',\n",
       " 'tell',\n",
       " 'room',\n",
       " 'took',\n",
       " 'went',\n",
       " 'day',\n",
       " 'make',\n",
       " 'look',\n",
       " 'door',\n",
       " 'll',\n",
       " 'better',\n",
       " 'just',\n",
       " 'head',\n",
       " 'sure',\n",
       " 'life',\n",
       " 'voice',\n",
       " 'hands',\n",
       " 'began',\n",
       " 'replied',\n",
       " 'place',\n",
       " 'heart',\n",
       " 'moment',\n",
       " 'answered',\n",
       " 'thing',\n",
       " 'word',\n",
       " 'right',\n",
       " 'heard',\n",
       " 'mrs',\n",
       " 'father',\n",
       " 'round',\n",
       " 'lady',\n",
       " 'got',\n",
       " 'half',\n",
       " 'turned',\n",
       " 'knew',\n",
       " 'looking',\n",
       " 'brother',\n",
       " 'saw',\n",
       " 'told',\n",
       " 'woman',\n",
       " 'returned',\n",
       " 'miss',\n",
       " 'left']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# //// nltk stopwords 확인 / svd 예측실패한 텍스트 중에 단어수가 50 이상인 것들 stopwords에 추가(odin은 제외)\n",
    "# 이건 내 주피터에서만 보이는거고 /////// 밑으로 추가한 것들\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almost choking much much wanted strange exclam...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sister suppose</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>engaged one walked perusing jane last letter d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>captain porch keeping carefully treacherous sh...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mercy gentlemen odin flung  write anyway shame...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54874</th>\n",
       "      <td>smith odin whispered  hardly dared hope would</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54875</th>\n",
       "      <td>plan captain us settled details accomplishment</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54876</th>\n",
       "      <td>sincere well wisher friend sister lucy odin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54877</th>\n",
       "      <td>wanted lend money</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54878</th>\n",
       "      <td>certainly occurred</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54879 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  author\n",
       "0      almost choking much much wanted strange exclam...       3\n",
       "1                                         sister suppose       2\n",
       "2      engaged one walked perusing jane last letter d...       1\n",
       "3      captain porch keeping carefully treacherous sh...       4\n",
       "4      mercy gentlemen odin flung  write anyway shame...       3\n",
       "...                                                  ...     ...\n",
       "54874      smith odin whispered  hardly dared hope would       2\n",
       "54875     plan captain us settled details accomplishment       4\n",
       "54876        sincere well wisher friend sister lucy odin       1\n",
       "54877                                  wanted lend money       3\n",
       "54878                                 certainly occurred       0\n",
       "\n",
       "[54879 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords 적용\n",
    "train.text = train.text.astype('str').str.split(' ')\n",
    "train['text'] = train['text'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "train['text'] = train['text'].apply(lambda x : (' ').join(x))\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.loc[:, 'text']\n",
    "y = train.loc[:, 'author']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:04.598129Z",
     "start_time": "2020-11-08T07:40:04.547395Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 벡터라이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:07.212166Z",
     "start_time": "2020-11-08T07:40:04.600620Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# TF-IDF Vectorization 적용하여 학습 데이터셋과 테스트 데이터 셋 변환.\n",
    "tfidf_vect = CountVectorizer(stop_words='english')\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T02:08:21.744983Z",
     "start_time": "2020-11-03T02:08:21.742825Z"
    }
   },
   "source": [
    "#### Multinomial Naive Bayes 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:07.235078Z",
     "start_time": "2020-11-08T07:40:07.213703Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mu_clf = MultinomialNB().fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:07.242504Z",
     "start_time": "2020-11-08T07:40:07.238372Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정식으로 pipeline을 만들고\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:07.281957Z",
     "start_time": "2020-11-08T07:40:07.245213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB train accuracy score: 0.7595152950823406\n",
      "MultinomialNB test accuracy score: 0.6868622448979592\n"
     ]
    }
   ],
   "source": [
    "# 학습 후 train, test accuracy score 적용\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mu_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "train_pred = mu_clf.predict(X_train_tfidf_vect)\n",
    "test_pred = mu_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('MultinomialNB train accuracy score:', accuracy_score(y_train, train_pred))\n",
    "print('MultinomialNB test accuracy score:', accuracy_score(y_test, test_pred))\n",
    "# predicted = text_clf.predict(X_test)\n",
    "\n",
    "# np.mean(predicted == y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:07.364785Z",
     "start_time": "2020-11-08T07:40:07.283608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79     10512\n",
      "           1       0.94      0.59      0.73      5841\n",
      "           2       0.85      0.68      0.76      9222\n",
      "           3       0.66      0.96      0.78     12034\n",
      "           4       0.97      0.49      0.65      6294\n",
      "\n",
      "    accuracy                           0.76     43903\n",
      "   macro avg       0.83      0.72      0.74     43903\n",
      "weighted avg       0.80      0.76      0.75     43903\n",
      "\n",
      "-------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.79      0.72      2723\n",
      "           1       0.89      0.50      0.64      1381\n",
      "           2       0.76      0.57      0.65      2332\n",
      "           3       0.61      0.92      0.73      3029\n",
      "           4       0.93      0.37      0.53      1511\n",
      "\n",
      "    accuracy                           0.69     10976\n",
      "   macro avg       0.77      0.63      0.66     10976\n",
      "weighted avg       0.73      0.69      0.67     10976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# print(confusion_matrix(y_test, pred))\n",
    "# print('-'*50)\n",
    "print(classification_report(y_train, train_pred))\n",
    "print('-----------'*5)\n",
    "print(classification_report(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 모델들 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:10.943813Z",
     "start_time": "2020-11-08T07:40:10.388247Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier,\n",
    "                              RandomForestClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "models = []\n",
    "models.append(('LogisticRegression', LogisticRegression(random_state=13)))\n",
    "models.append(('MultinomialNB', MultinomialNB()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier(random_state=13, n_jobs=-1)))\n",
    "models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=13)))\n",
    "models.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=13)))\n",
    "models.append(('GradientBoostingClassifier', GradientBoostingClassifier(random_state=13)))\n",
    "models.append(('LGBMClassifier', LGBMClassifier(random_state=13)))\n",
    "models.append(('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)))\n",
    "models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', random_state=13)))\n",
    "models.append(('XgBoost', XGBClassifier(learning_rate=0.1, max_depth=3, random_state=13, n_jobs=-1)))\n",
    "models.append(('RidgeClassifier', RidgeClassifier(random_state=13)))\n",
    "models.append(('SGDClassifier', SGDClassifier(random_state=13, loss='modified_huber')))\n",
    "# models.append(('RidgeClassifierCV', RidgeClassifierCV(cv=3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:40:10.957295Z",
     "start_time": "2020-11-08T07:40:10.946031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LogisticRegression', LogisticRegression(random_state=13)),\n",
       " ('MultinomialNB', MultinomialNB()),\n",
       " ('RandomForestClassifier',\n",
       "  RandomForestClassifier(n_jobs=-1, random_state=13)),\n",
       " ('DecisionTreeClassifier', DecisionTreeClassifier(random_state=13)),\n",
       " ('AdaBoostClassifier', AdaBoostClassifier(random_state=13)),\n",
       " ('GradientBoostingClassifier', GradientBoostingClassifier(random_state=13)),\n",
       " ('LGBMClassifier', LGBMClassifier(random_state=13)),\n",
       " ('KNeighborsClassifier', KNeighborsClassifier(n_jobs=-1)),\n",
       " ('LinearSVC', LinearSVC(C=1, loss='hinge', random_state=13)),\n",
       " ('XgBoost',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=0.1, max_delta_step=None, max_depth=3,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
       "                random_state=13, reg_alpha=None, reg_lambda=None,\n",
       "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                validate_parameters=None, verbosity=None)),\n",
       " ('RidgeClassifier', RidgeClassifier(random_state=13)),\n",
       " ('SGDClassifier', SGDClassifier(loss='modified_huber', random_state=13))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:45:37.154009Z",
     "start_time": "2020-11-08T07:40:10.959239Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:45:37.170161Z",
     "start_time": "2020-11-08T07:45:37.156009Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score})\n",
    "result['diff'] = result['train score'] - result['test score']\n",
    "result.round(2).sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T05:44:44.334574Z",
     "start_time": "2020-11-04T05:44:44.329602Z"
    }
   },
   "source": [
    "## 모델 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:45:40.209142Z",
     "start_time": "2020-11-08T07:45:37.171793Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect = CountVectorizer(stop_words='english')\n",
    "tfidf_vect.fit(X_train)\n",
    "X_train_tfidf_vect = tfidf_vect.transform(X_train)\n",
    "X_test_tfidf_vect = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:15.250637Z",
     "start_time": "2020-11-08T07:51:12.965910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB best parameters: {'alpha': 0.1, 'fit_prior': 'True'}\n",
      "MultinomialNB best accuracy score: 0.6973555459276265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "         'fit_prior': ['True', 'False']}\n",
    "clf = MultinomialNB()\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('MultinomialNB best parameters:', grid_cv.best_params_)\n",
    "print('MultinomialNB best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:15.288123Z",
     "start_time": "2020-11-08T07:51:15.253169Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB train accuracy score 0.7898093524360522\n",
      "MultinomialNB test accuracy score 0.7090014577259475\n"
     ]
    }
   ],
   "source": [
    "mu_clf = MultinomialNB(alpha=0.1, fit_prior='True')\n",
    "mu_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "mu_train_pred = mu_clf.predict(X_train_tfidf_vect)\n",
    "mu_test_pred = mu_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('MultinomialNB train accuracy score', accuracy_score(y_train, mu_train_pred))\n",
    "print('MultinomialNB test accuracy score', accuracy_score(y_test, mu_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:15.292742Z",
     "start_time": "2020-11-08T07:51:15.290389Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:15.454289Z",
     "start_time": "2020-11-08T07:51:15.294670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01744914, 0.01574397, 0.01484299, 0.01434803, 0.01811409]),\n",
       " 'score_time': array([0.00300908, 0.00269103, 0.00261188, 0.00249028, 0.00424099]),\n",
       " 'test_score': array([0.70606992, 0.70276734, 0.69866758, 0.70615034, 0.70649203]),\n",
       " 'train_score': array([0.79468709, 0.7950857 , 0.79693639, 0.79500612, 0.79452211])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(mu_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:19.539894Z",
     "start_time": "2020-11-08T07:51:15.456254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8779582260893333\n",
      "LinearSVC test accuracy score: 0.6758381924198251\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc_clf = LinearSVC(C=1, loss='hinge', random_state=13)\n",
    "svc_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "svc_train_pred = svc_clf.predict(X_train_tfidf_vect)\n",
    "svc_test_pred = svc_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, svc_train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, svc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:48.074823Z",
     "start_time": "2020-11-08T07:51:19.541912Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l1, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=squared_hinge, penalty=l2, random_state=13 ........\n",
      "[CV]  C=0.001, loss=squared_hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l1, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.2s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.001, loss=hinge, penalty=l2, random_state=13 ................\n",
      "[CV] . C=0.001, loss=hinge, penalty=l2, random_state=13, total=   0.3s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l1, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.6s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.6s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.6s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.7s\n",
      "[CV] C=0.01, loss=squared_hinge, penalty=l2, random_state=13 .........\n",
      "[CV]  C=0.01, loss=squared_hinge, penalty=l2, random_state=13, total=   0.8s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l1, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.5s\n",
      "[CV] C=0.01, loss=hinge, penalty=l2, random_state=13 .................\n",
      "[CV] .. C=0.01, loss=hinge, penalty=l2, random_state=13, total=   0.4s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l1, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   5.6s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   5.1s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   5.5s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   5.1s\n",
      "[CV] C=1, loss=squared_hinge, penalty=l2, random_state=13 ............\n",
      "[CV]  C=1, loss=squared_hinge, penalty=l2, random_state=13, total=   5.5s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l1, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l1, random_state=13, total=   0.0s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   4.9s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   5.4s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   4.8s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   4.3s\n",
      "[CV] C=1, loss=hinge, penalty=l2, random_state=13 ....................\n",
      "[CV] ..... C=1, loss=hinge, penalty=l2, random_state=13, total=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearSVC(),\n",
       "             param_grid={'C': [0.001, 0.01, 1],\n",
       "                         'loss': ['squared_hinge', 'hinge'],\n",
       "                         'penalty': ['l1', 'l2'], 'random_state': [13]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.001, 0.01, 1], \n",
    "    'loss': ['squared_hinge', 'hinge'], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'random_state': [13]\n",
    "    }\n",
    "\n",
    "grid_cv = GridSearchCV(LinearSVC(), param_grid=params, refit=True, verbose=2)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:48.081324Z",
     "start_time": "2020-11-08T07:51:48.078320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Best parameters: {'C': 1, 'loss': 'hinge', 'penalty': 'l2', 'random_state': 13}\n",
      "LinearSVC Best accruacy score: 0.6715714193437426\n"
     ]
    }
   ],
   "source": [
    "print('LinearSVC Best parameters:', grid_cv.best_params_)\n",
    "print('LinearSVC Best accruacy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:51.927031Z",
     "start_time": "2020-11-08T07:51:48.083685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC train accuracy score: 0.8779582260893333\n",
      "LinearSVC test accuracy score: 0.6758381924198251\n"
     ]
    }
   ],
   "source": [
    "svc_svm_clf = LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)\n",
    "svc_svm_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "svc_train_pred = svc_svm_clf.predict(X_train_tfidf_vect)\n",
    "svc_test_pred = svc_svm_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LinearSVC train accuracy score:', accuracy_score(y_train, svc_train_pred))\n",
    "print('LinearSVC test accuracy score:', accuracy_score(y_test, svc_test_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:51.934128Z",
     "start_time": "2020-11-08T07:51:51.928653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False, False, False],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False, False, False,  True],\n",
       "       ...,\n",
       "       [False, False, False, False, False],\n",
       "       [False, False, False,  True, False],\n",
       "       [False, False, False, False,  True]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_svm_clf.decision_function(X_test_tfidf_vect) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:51:51.939645Z",
     "start_time": "2020-11-08T07:51:51.936972Z"
    }
   },
   "outputs": [],
   "source": [
    "# 교차검증\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:52:21.379442Z",
     "start_time": "2020-11-08T07:51:51.942230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([6.16752315, 4.66517401, 4.4836328 , 4.46567297, 4.46346092,\n",
       "        4.33517289, 4.37541413, 4.35532808, 4.36853671, 4.40511298]),\n",
       " 'score_time': array([0.00145197, 0.00146794, 0.00146294, 0.00170588, 0.00146818,\n",
       "        0.00142527, 0.00148392, 0.00146604, 0.00146031, 0.00145483]),\n",
       " 'test_score': array([0.6745616 , 0.67205648, 0.68890913, 0.67061503, 0.68724374,\n",
       "        0.67266515, 0.66970387, 0.67995444, 0.68633257, 0.676082  ]),\n",
       " 'train_score': array([0.88284572, 0.88203584, 0.88064386, 0.88155797, 0.88122896,\n",
       "        0.88100119, 0.88355731, 0.88049503, 0.88105181, 0.88360793])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "\n",
    "cross_validate(svc_svm_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:52:21.917482Z",
     "start_time": "2020-11-08T07:52:21.381045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier train accuracy score: 0.8757715873630504\n",
      "SGDClassifier test accuracy score: 0.6860422740524781\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=13, loss='modified_huber')\n",
    "sgd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "sgd_train_pred = sgd_clf.predict(X_train_tfidf_vect)\n",
    "sgd_test_pred = sgd_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('SGDClassifier train accuracy score:', accuracy_score(y_train, sgd_train_pred))\n",
    "print('SGDClassifier test accuracy score:', accuracy_score(y_test, sgd_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:52:23.963574Z",
     "start_time": "2020-11-08T07:52:21.919168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69069582, 0.68409065, 0.67828266, 0.68462415, 0.68291572])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 교차 검증\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_tfidf_vect, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:52:25.087129Z",
     "start_time": "2020-11-08T07:52:23.966437Z"
    }
   },
   "outputs": [],
   "source": [
    "# 오차 행렬\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_tfidf_vect, y_train, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:52:25.132422Z",
     "start_time": "2020-11-08T07:52:25.089194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6701,  624, 1182, 1525,  480],\n",
       "       [ 588, 3643,  660,  751,  199],\n",
       "       [ 819,  314, 6340, 1228,  521],\n",
       "       [ 921,  398, 1193, 9187,  335],\n",
       "       [ 741,  250,  936,  820, 3547]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:53:30.430225Z",
     "start_time": "2020-11-08T07:52:25.134339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=SGDClassifier(loss='modified_huber', random_state=13),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0,\n",
       "                                   1000.0],\n",
       "                         'loss': ['log', 'modified_huber', 'hinge',\n",
       "                                  'squared_hinge', 'perceptron'],\n",
       "                         'n_jobs': [-1], 'penalty': ['l2', 'elasticnet'],\n",
       "                         'random_state': [13]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "    'loss': ['log', 'modified_huber', 'hinge', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [13],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(sgd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:53:30.435273Z",
     "start_time": "2020-11-08T07:53:30.432112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier best parameters: {'alpha': 0.0001, 'loss': 'hinge', 'n_jobs': -1, 'penalty': 'l2', 'random_state': 13}\n",
      "SGDClassifier best accuracy score: 0.6768785531684797\n"
     ]
    }
   ],
   "source": [
    "print('SGDClassifier best parameters:', grid_cv.best_params_)\n",
    "print('SGDClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:53:32.437626Z",
     "start_time": "2020-11-08T07:53:30.437316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.52907896, 0.4407208 , 0.462749  , 0.46754003, 0.40408301]),\n",
       " 'score_time': array([0.003371  , 0.00250316, 0.00320697, 0.00242591, 0.00259304]),\n",
       " 'test_score': array([0.69069582, 0.68409065, 0.67828266, 0.68462415, 0.68291572]),\n",
       " 'train_score': array([0.88918627, 0.88947099, 0.88930015, 0.88787974, 0.8856305 ])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cross_validate(sgd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skfold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:53:56.631691Z",
     "start_time": "2020-11-08T07:53:32.440103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best parameters: {'alpha': 1.0, 'max_iter': 100, 'normalize': True, 'random_state': 13}\n",
      "RidgeClassifier best accuracy score: 0.6520740179500645\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier()\n",
    "params = {\n",
    "    'alpha': [0.01, 0.1, 0.5, 1.0],\n",
    "    'normalize': [True, False],\n",
    "    'max_iter': [100, 300],\n",
    "    'random_state': [13]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(rd_clf, param_grid=params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('RidgeClassifier best parameters:', grid_cv.best_params_)\n",
    "print('RidgeClassifier best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:53:57.183228Z",
     "start_time": "2020-11-08T07:53:56.634282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier best train accuracy score: 0.8070519098922625\n",
      "RidgeClassifier best test accuracy score: 0.6662718658892128\n"
     ]
    }
   ],
   "source": [
    "rd_clf = RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)\n",
    "rd_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "rd_train_pred = rd_clf.predict(X_train_tfidf_vect)\n",
    "rd_test_pred = rd_clf.predict(X_test_tfidf_vect)\n",
    "print('RidgeClassifier best train accuracy score:', accuracy_score(y_train, rd_train_pred))\n",
    "print('RidgeClassifier best test accuracy score:', accuracy_score(y_test, rd_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:54:02.521956Z",
     "start_time": "2020-11-08T07:53:57.186128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.30153608, 0.30646992, 0.29524517, 0.29197907, 0.35633206,\n",
       "        0.321141  , 0.31069326, 0.30892611, 0.30994701, 0.32381511]),\n",
       " 'score_time': array([0.00180912, 0.002105  , 0.00191617, 0.00181198, 0.00201082,\n",
       "        0.00224304, 0.00175691, 0.00173998, 0.00188708, 0.00187492]),\n",
       " 'test_score': array([0.66545206, 0.65839217, 0.66977909, 0.65968109, 0.66993166,\n",
       "        0.66355353, 0.65740319, 0.67312073, 0.66492027, 0.66218679]),\n",
       " 'train_score': array([0.80990585, 0.81190524, 0.81066511, 0.81066991, 0.8103409 ,\n",
       "        0.81153038, 0.81135323, 0.81051806, 0.81142915, 0.81218839])}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(rd_clf, X_train_tfidf_vect, y_train, scoring=None, cv=skf, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:55:57.644815Z",
     "start_time": "2020-11-08T07:54:02.530867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression best parameters: {'C': 1.0, 'max_iter': 100}\n",
      "LogisticRegression best accuracy score: 0.6820719149520125\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "params = {\n",
    "    'C': [0.01, 0.1, 0.5, 1.0],\n",
    "    'max_iter': [100, 200, 500],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(clf, param_grid=params, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid_cv.fit(X_train_tfidf_vect, y_train)\n",
    "print('LogisticRegression best parameters:', grid_cv.best_params_)\n",
    "print('LogisticRegression best accuracy score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T07:56:14.459936Z",
     "start_time": "2020-11-08T07:55:57.649761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy score: 0.8671616973783113\n",
      "LogisticRegression test accuracy score: 0.684402332361516\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(C=1.0, max_iter=500)\n",
    "lr_clf.fit(X_train_tfidf_vect, y_train)\n",
    "\n",
    "lr_train_pred = lr_clf.predict(X_train_tfidf_vect)\n",
    "lr_test_pred = lr_clf.predict(X_test_tfidf_vect)\n",
    "\n",
    "print('LogisticRegression train accuracy score:', accuracy_score(y_train, lr_train_pred))\n",
    "print('LogisticRegression test accuracy score:', accuracy_score(y_test, lr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:19.612737Z",
     "start_time": "2020-11-08T08:04:19.376498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>odin</td>\n",
       "      <td>1790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4305</th>\n",
       "      <td>mind</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>mean</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2937</th>\n",
       "      <td>going</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>morning</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>hypothetical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>hypothesis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>hymn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>hydraulics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>zigzag</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7820 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1\n",
       "4642          odin  1790\n",
       "4305          mind    61\n",
       "4213          mean    56\n",
       "2937         going    55\n",
       "4401       morning    54\n",
       "...            ...   ...\n",
       "3388  hypothetical     1\n",
       "3387    hypothesis     1\n",
       "3386          hymn     1\n",
       "3385    hydraulics     1\n",
       "7819        zigzag     1\n",
       "\n",
       "[7820 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "abc = pd.merge(X_test, y_test, left_index = True, right_index=True)\n",
    "abc['pred'] = sgd_test_pred\n",
    "\n",
    "# 예측이 틀린 결과 -> 데이터 프레임 화\n",
    "error_df = abc[abc['author'] != abc['pred']]\n",
    "\n",
    "# CountVectorizer로 단어 갯수 카운트\n",
    "cv = CountVectorizer(stop_words='english')   \n",
    "cv_fit=cv.fit_transform(error_df['text'])    \n",
    "word_list = cv.get_feature_names();    \n",
    "count_list = cv_fit.toarray().sum(axis=0)\n",
    "\n",
    "di = dict(zip(word_list,count_list))\n",
    "\n",
    "# 예측이 틀린 결과 중 가장 많이 나온 단어 20개 정렬\n",
    "miss = pd.DataFrame(list(di.items())).sort_values(by=1, ascending=False)\n",
    "miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odin',\n",
       " 'mind',\n",
       " 'mean',\n",
       " 'going',\n",
       " 'morning',\n",
       " 'mother',\n",
       " 'sat',\n",
       " 'ill',\n",
       " 'leave',\n",
       " 'home',\n",
       " 'poor']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miss[miss[1] >= 50][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:19.617328Z",
     "start_time": "2020-11-08T08:04:19.614903Z"
    }
   },
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# cb = CatBoostClassifier(silent=True, random_state=13, n_estimators=300).fit(X_train_tfidf_vect, y_train)\n",
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))\n",
    "# accuracy_score(y_test, cb.predict(X_test_tfidf_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:19.621687Z",
     "start_time": "2020-11-08T08:04:19.619345Z"
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score(y_train, cb.predict(X_train_tfidf_vect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:19.628987Z",
     "start_time": "2020-11-08T08:04:19.623714Z"
    }
   },
   "outputs": [],
   "source": [
    "t_models = []\n",
    "\n",
    "t_models.append(('MultinomialNB', MultinomialNB(alpha=0.5, fit_prior='True')))\n",
    "t_models.append(('LinearSVC', LinearSVC(C=1, loss='hinge', penalty='l2', random_state=13)))\n",
    "t_models.append(('SGDClassifier', SGDClassifier(alpha=0.0001, loss='modified_huber', n_jobs=-1, penalty='l2', random_state=13)))\n",
    "t_models.append(('RidgeClassifier', RidgeClassifier(alpha=1.0, max_iter=100, normalize='False', random_state=13)))\n",
    "t_models.append(('LogisticRegression', LogisticRegression(C=1.0, max_iter=500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:41.058513Z",
     "start_time": "2020-11-08T08:04:19.630932Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_score = []\n",
    "test_score = []\n",
    "names = []\n",
    "\n",
    "for name, model in t_models:\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf_vect, y_train)\n",
    "    \n",
    "    train_pred = clf.predict(X_train_tfidf_vect)\n",
    "    test_pred = clf.predict(X_test_tfidf_vect)\n",
    "    \n",
    "    names.append(name)\n",
    "    train_score.append(accuracy_score(y_train, train_pred))\n",
    "    test_score.append(accuracy_score(y_test, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:04:41.085534Z",
     "start_time": "2020-11-08T08:04:41.061559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>train score</th>\n",
       "      <th>test score</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model name  train score  test score  diff\n",
       "0           LinearSVC         0.88        0.68  0.20\n",
       "1       SGDClassifier         0.88        0.69  0.19\n",
       "2  LogisticRegression         0.87        0.68  0.18\n",
       "3     RidgeClassifier         0.81        0.67  0.14\n",
       "4       MultinomialNB         0.78        0.71  0.07"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model name': names,\n",
    "                       'train score': train_score,\n",
    "                       'test score': test_score})\n",
    "result['diff'] = result['train score'] - result['test score']\n",
    "result.round(2).sort_values(by='train score', ascending=False).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
